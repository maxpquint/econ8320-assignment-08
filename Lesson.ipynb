{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91105c67-00f5-4277-a8ea-c63cae87142c",
   "metadata": {
    "id": "91105c67-00f5-4277-a8ea-c63cae87142c"
   },
   "source": [
    "## Arrays and Math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e92ef-f8e2-4ab0-bc7b-5b2c01eda24f",
   "metadata": {
    "id": "880e92ef-f8e2-4ab0-bc7b-5b2c01eda24f",
    "tags": []
   },
   "source": [
    "A while back, we created some matrix code using lists (I hope bringing this up doesn't trigger any PTSD from that experience...). These list-based matrices \"work\" in the sense that it is possible for us to construct matrices using lists, and it is possible for us to write code to do calculations with them. We have not yet tried to do any real computation with those tools, however. Doing so will make us regret our choice to implement matrix operations using lists. We will wish that there were a better way to do complex operations without the headaches of checking, rechecking, and worrying about having missed some critical part of the computation in our own code. (Matrix algebra is just a lot of steps, and hard to get right when you're still learning to code.)\n",
    "\n",
    "Despite this knowledge, let's get started by writing some simple computations in pure Python to work with our \"matrices\" stored in lists. Let's calculate the dot product of two vectors of equal length as a first exercise.\n",
    "\n",
    "### Calculating Dot Products\n",
    "\n",
    "The **dot product** of two vectors is the sum of the products of the corresponding elements in each vector. We can write it as follows:\n",
    "\n",
    "$$ a \\cdot b = \\sum_{i=1}^N a_i \\times b_i $$\n",
    "\n",
    "In other words, a dot product of two vectors (they MUST be of equal length) is calculated as the sum of the products of values in corresponding positions within the vectors. We need to walk through each position within our vectors, multiplying the values in the same position, and then adding all these products together. If we try this in code, we might write the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc63035-9187-4bea-bf8a-46498f0377e0",
   "metadata": {
    "id": "7bc63035-9187-4bea-bf8a-46498f0377e0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dotProd(v1, v2): # Define our function and arguments\n",
    "    if len(v1) is len(v2): # Test equality of vector length\n",
    "        dp = 0               # Initialize Dot Product Value\n",
    "        for i in range(len(v1)): # Loop over all elements\n",
    "            dp += v1[i]*v2[i]      # Add elements of the sum\n",
    "        return dp            # Return the dot product\n",
    "    else: # If vetors are of unequal length, return error\n",
    "        raise RuntimeError(\"Vectors must be of equal length\")\n",
    "\n",
    "dotProd([1,2,3], [7,10,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8174c2-9511-442d-b7bf-527de4caf856",
   "metadata": {
    "id": "1e8174c2-9511-442d-b7bf-527de4caf856",
    "tags": []
   },
   "source": [
    "Let's check by hand:\n",
    "\n",
    "$$ 1*7 + 2*10 + 3*1 = 7 + 20 + 3 = 30 $$\n",
    "\n",
    "\n",
    "### Matrix Multiplication\n",
    "\n",
    "In order to get to the point where we can do some real heavy lifting with matrices (solve systems of equations, etc.), we need to multiply two matrices together. This is possible when the number of columns in the first matrix are equal to the number of rows in the second matrix. We call two matrices that have this property relative to one another **conforming** matrices. It is also important to note that if $ A\\times B $ is conforming this does NOT necessarily mean that $B\\times A$ is conforming! Order matters with matrices! If\n",
    "\n",
    "- $A$ is an $m \\times n$ matrix (has $m$ rows, $n$ columns)\n",
    "\n",
    "- $B$ is an $n \\times q$ matrix (has $n$ rows, $q$ columns)\n",
    "\n",
    "then the matrices are conforming, and can be multiplied together. The resulting matrix, $C$ is an $m \\times q$ matrix.\n",
    "\n",
    "The math to calculate multiplication of two matrices is somewhat complex. Here is an example of how it works:\n",
    "\n",
    "$$\n",
    "A =\n",
    "  \\begin{bmatrix}\n",
    "    1 & 2 \\\\\n",
    "    3 & 4\n",
    "  \\end{bmatrix},\n",
    "B =\n",
    "  \\begin{bmatrix}\n",
    "    6 \\\\\n",
    "    5\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Matrix $A$ has 2 columns, and $B$ has 2 rows (conforming).\n",
    "\n",
    "$$\n",
    "AB = C  = \\begin{bmatrix}\n",
    "    1\\cdot 6 + 2\\cdot5 \\\\\n",
    "    3\\cdot 6 + 4\\cdot5\n",
    "  \\end{bmatrix} =\n",
    "  \\begin{bmatrix}\n",
    "    16 \\\\\n",
    "    38\n",
    "  \\end{bmatrix} \\checkmark $$\n",
    "\n",
    "The more general pattern for matrix multiplication is as follows:\n",
    "\n",
    "$$\n",
    "A =\n",
    "  \\begin{bmatrix}\n",
    "    a_{1,1} & \\cdots & a_{1,m}\\\\\n",
    "    \\vdots & \\ddots & \\vdots\\\\\n",
    "    a_{n,1} & \\cdots & a_{n,m}\n",
    "  \\end{bmatrix},\n",
    "B =\n",
    "    \\begin{bmatrix}\n",
    "    b_{1,1} & \\cdots & b_{1,p}\\\\\n",
    "    \\vdots & \\ddots & \\vdots\\\\\n",
    "    b_{m,1} & \\cdots & b_{m,p}\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Matrix $A$ has $m$ columns, and $B$ has $m$ rows (conforming). C will have shape $n \\times p$\n",
    "\n",
    "$$ c_{ij} = \\sum_{k=1}^m a_{ik} \\times b_{kj} $$\n",
    "\n",
    "We calculate all elements of $C$ in this manner. One last way to look at this is with the following visual guide:\n",
    "\n",
    "![](https://github.com/dustywhite7/Econ8320/raw/master/SlidesCode/matMult.png)\n",
    "\n",
    "\n",
    "Now that we have looked at this process in significant detail, let's write an algorithm to perform arbitrary matrix multiplication given two conforming matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1941e-8b57-4d31-99d6-a1dbd70fac8b",
   "metadata": {
    "id": "9ce1941e-8b57-4d31-99d6-a1dbd70fac8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def matMul(a, b): # Define function, take 2 matrices\n",
    "    for i in range(len(a)): # Make sure a is matrix\n",
    "        if len(a[i]) is not len(a[0]): # If not,\n",
    "            raise RuntimeError( # Raise an error\n",
    "            \"Matrix A is not correctly specified\")\n",
    "    for i in range(len(b)): # Make sure b is a matrix\n",
    "        if len(b[i]) is not len(b[0]): # If not,\n",
    "            raise RuntimeError( # Raise an error\n",
    "            \"Matrix B is not correctly specified\")\n",
    "    matrix = [] # Initialize new empty matrix\n",
    "    if len(a[0]) is len(b): # Test for conformability\n",
    "        for i in range(len(a)): # Iterate over rows of a\n",
    "            row = [] # Create row of new matrix\n",
    "            for j in range(len(b[0])): # Iterate over columns\n",
    "                row.append(dotProd(a[i], # Append elements of col\n",
    "                  [b[n][j] for n in range(len(b))]))\n",
    "                matrix.append(row) # Append rows to matrix\n",
    "        return matrix # Return the newly calculated matrix\n",
    "    else: # If matrices are nonconforming\n",
    "        raise RuntimeError( #Raise an error\n",
    "        \"Matrices are nonconformable for multiplication\")\n",
    "\n",
    "A = [[1,2],[3,4]]\n",
    "B = [[6],[5]]\n",
    "\n",
    "matMul(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861a515e-1864-452d-be77-e9dc6caf492b",
   "metadata": {
    "id": "861a515e-1864-452d-be77-e9dc6caf492b",
    "tags": []
   },
   "source": [
    "Since we did this problem by hand before writing our code, we know that we got the right answer. Yay! But, really, that was a lot of annoying code to write... It's great that Python is so flexible that we can quickly write functions to do calculations like matrix multiplication. Do we WANT to write out functions to do all of the mathematical processes we need for different kinds of analysis? Random number generators? Matrix inversion algorithms? Solving matrix equalities?\n",
    "\n",
    "![w:500](https://steamuserimages-a.akamaihd.net/ugc/1002555926635405089/63B75F86672E6D0197144382C960EAF51DFF5E21/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f4e9eb-ed4c-4682-ba08-59b705931c07",
   "metadata": {
    "id": "17f4e9eb-ed4c-4682-ba08-59b705931c07"
   },
   "source": [
    "## Numeric Python (Numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88687e78-dc42-4597-afe4-cf1555001a57",
   "metadata": {
    "id": "88687e78-dc42-4597-afe4-cf1555001a57"
   },
   "source": [
    "Instead of writing our own algorithms, sometimes (pretty much all the time if we are honest) we prefer libraries with pre-written (and far more efficient) algorithms to solve complex mathematical problems. The `numpy` library is that library in Python. Its full documentation is available here: [Numpy Reference Page](https://docs.scipy.org/doc/numpy/reference/index.html).\n",
    "\n",
    "There are a few reasons that we would strongly prefer `numpy` to our own code:\n",
    "1. Many eyes - there are many, many contributors to the `numpy` project, so that bugs are worked out much more quickly than would happen on our own code\n",
    "2. Underlying code is C++/Fortran - it turns out that Python is actually a pretty slow programming language when all of your code is written in pure python. `numpy` gets around this problem by being a library that actually contains Python code to interact with algorithms written in much faster languages like C++ and Fortran. This means that we get REALLY fast code, but without the burden of needing to learn more difficult programming languages\n",
    "3. Well-seasoned - `numpy` has been around a long time (since at least 2006, maybe 1995 depending on how you look at it). This means that it has had lots of time to build up capabilities and functionality. It does pretty much all the things! Next week we will finish covering `numpy` with `scipy`, and then they really DO do all of the things. (haha... do do... 💩... sorry...)\n",
    "\n",
    "\n",
    "Now that we know it exists (and have hopefully motivated you by explaining its value), let's learn how to use `numpy`! So much time saving!\n",
    "\n",
    "### `numpy` arrays\n",
    "\n",
    "The building blocks of `numpy` are arrays. Arrays can essentially be treated as equivalent to mathematical matrices (and vectors), and are a special object type that takes data and stores it in formats that allow us to more easily apply mathematical functions to that data. The big advantage of arrays is that the entire array must be of a certain type. If entries in an array are non-numeric, then the whole array is treated as non-numeric (called `object` arrays). If we have some `int` and some `float` values, the array becomes `float`. This allows us to homogenize operations across arrays.\n",
    "\n",
    "Arrays can have any number of dimensions, from 1 to whatever violates your computer's memory constraints. In this course we will generally deal with 1- and 2-dimensional arrays. Arrays work differently than lists of lists because they require that our data be **rectangular**. In other words, if we have 3 columns in one row, we must also have 3 columns in the other rows. Before we get too far into the nitty gritty, let's take a look at how we *create* arrays. We will focus on creating arrays in two ways:\n",
    "1. Creating arrays by coercing lists and tuples to the array type\n",
    "2. Creating arrays using `numpy` commands\n",
    "\n",
    "#### Array Creation via List Coercion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c3c30-45dc-49d2-9074-5c4e1b15042c",
   "metadata": {
    "id": "7c0c3c30-45dc-49d2-9074-5c4e1b15042c"
   },
   "outputs": [],
   "source": [
    "import numpy as np # import library as np object\n",
    "\n",
    "myList = [1, 2, 3, 4]\n",
    "myArray = np.array(myList)\n",
    "myArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60d9f6-ee20-4599-98c8-feaabc224658",
   "metadata": {
    "id": "1d60d9f6-ee20-4599-98c8-feaabc224658"
   },
   "source": [
    "Cool! We created a list, and transformed it into a 1-dimensional array. How do I know that it is a 1-dimensional array? We can use the `.shape` attribute to check for ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe1b172-8270-46f4-86e0-f7984f39ee95",
   "metadata": {
    "id": "5fe1b172-8270-46f4-86e0-f7984f39ee95"
   },
   "outputs": [],
   "source": [
    "myArray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16ebcd-cd6d-4433-8aa4-f6f473994198",
   "metadata": {
    "id": "1f16ebcd-cd6d-4433-8aa4-f6f473994198",
    "tags": []
   },
   "source": [
    "This `shape` attribute will help us to ensure that we understand the structure of any arrays we are working with. The number of elements in the `shape` tuple tells us the dimensionality of our array, and the value in each position tells us the size of each dimension. In this case, we see that we have a 1-dimensional array, with 4 values.\n",
    "\n",
    "In sum, we can use the `np.array` function to generate an array from any arbitrary list (or tuple) of numbers.\n",
    "\n",
    "#### Array Creation Using Commands\n",
    "\n",
    "Sometimes we don't have data to put into our array quite yet, but we want to get it built out so that we can algorithmically update the array as data flows in. There are many commands that we can use to create arrays, depending on the kind of array that we need to build:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e540cddb-1987-4c87-9da9-0e58a396b7a9",
   "metadata": {
    "id": "e540cddb-1987-4c87-9da9-0e58a396b7a9",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.array([1,2,3,4]) # Specify each element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a850e-5be8-45d7-a491-0c27af1b55c4",
   "metadata": {
    "id": "ba7a850e-5be8-45d7-a491-0c27af1b55c4",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.zeros((3,3)) # Generate 3 x 3 array of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d47ddb0-74c6-4ff2-bcb1-137ff2e3c03b",
   "metadata": {
    "id": "0d47ddb0-74c6-4ff2-bcb1-137ff2e3c03b",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.eye(3) # Generate 3 x 3 identity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f920dbe3-514d-40b0-9334-729a0476e60f",
   "metadata": {
    "id": "f920dbe3-514d-40b0-9334-729a0476e60f",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "The `array`, `zeros`, and `eye` functions are all ways to create arrays in `numpy`. The `np.eye` function, in particular, allows us to quickly create matrices that are essential in matrix algebra, since the identity matrix is the matrix version of the number 1, and is used to manipulate equations as we look to solve them in various contexts.\n",
    "\n",
    "Many other functions exist to generate arrays that we won't cover, and there are a few more that we will cover later as we learn about other `numpy` functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c8c50-3eab-40ba-b8bf-9b9112da08d4",
   "metadata": {
    "id": "455c8c50-3eab-40ba-b8bf-9b9112da08d4"
   },
   "source": [
    "## Manipulation of Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a1875-3c50-4abd-8040-3546462b7ed3",
   "metadata": {
    "id": "919a1875-3c50-4abd-8040-3546462b7ed3"
   },
   "source": [
    "Once we create them, there are lots of things that we might want to do with our arrays, but some of the most basic are just transformations and manipulations of the arrays.\n",
    "\n",
    "First, we sometimes want to reshape our data. This may be because we store data in one shape or structure, but need to perform calculations using the data in a different structure. If we store image data for 28x28 pixel images in a spreadsheet, for example, we would have one row per image, and each row would have 784 columns. In order to render one row as an image, we could then transform a row back into a 28x28 obejct using the `.reshape` method. Let's take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68f8f9-775f-45eb-99e9-f88e8db72ac4",
   "metadata": {
    "id": "4c68f8f9-775f-45eb-99e9-f88e8db72ac4"
   },
   "outputs": [],
   "source": [
    "myArray = np.array([1,2,3,4]) # Specify each element\n",
    "np.shape(myArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96be259f-345e-4e4a-b95c-dd6eae210bf9",
   "metadata": {
    "id": "96be259f-345e-4e4a-b95c-dd6eae210bf9"
   },
   "source": [
    "Again, we will start with our 1-D array, and in the cell below, we will make it a 2-D array, or a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7499e20-4653-4098-8cea-f392d3bd7c15",
   "metadata": {
    "id": "c7499e20-4653-4098-8cea-f392d3bd7c15"
   },
   "outputs": [],
   "source": [
    "myArray = np.array([[1,2,3,4]])\n",
    "np.shape(myArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7409b7b-b8cb-4f1c-a129-79dc83b2e0c3",
   "metadata": {
    "id": "c7409b7b-b8cb-4f1c-a129-79dc83b2e0c3"
   },
   "source": [
    "Now we see that the array is 2-D (this happened because we coerced a list embedded in a list into an array). We can reshape the array to make a square matrix using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19486a06-319e-4568-91de-d4631154242c",
   "metadata": {
    "id": "19486a06-319e-4568-91de-d4631154242c"
   },
   "outputs": [],
   "source": [
    "myArray.reshape((2,2)) # transform to square matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c84e41-27f6-491c-8cc1-4cc295428ee7",
   "metadata": {
    "id": "02c84e41-27f6-491c-8cc1-4cc295428ee7"
   },
   "source": [
    "If we want to make it a matrix in one column rather than in one row, we can reshape accoringly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889d245-c6f7-4595-bd9c-6b57caca95f1",
   "metadata": {
    "id": "0889d245-c6f7-4595-bd9c-6b57caca95f1"
   },
   "outputs": [],
   "source": [
    "myArray.reshape((4,1)) # transform to column vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f523d08b-b1f7-4ddf-9abd-bed3a05d345d",
   "metadata": {
    "id": "f523d08b-b1f7-4ddf-9abd-bed3a05d345d"
   },
   "source": [
    "We can also transform a matrix by **transposing** the matrix. This means that we make each row into a column, and each column into a row (preserving order). In other words, we flip the matrix across the main diagonal (positions (1,1), (2,2), etc.). The transpose of an array is always stored in the attribute `.T`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f64469-20c4-4328-9b55-000bc26ff169",
   "metadata": {
    "id": "03f64469-20c4-4328-9b55-000bc26ff169"
   },
   "outputs": [],
   "source": [
    "myArray = np.array([[1,2,3,4]])\n",
    "myArray.T # transposes the array if 2-D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d199c2-5653-4e30-9a0f-4e514fea42cc",
   "metadata": {
    "id": "36d199c2-5653-4e30-9a0f-4e514fea42cc"
   },
   "source": [
    "### Math Operations on Matrices/Arrays\n",
    "\n",
    "Now that we can create and shape matrices, it's time to start doing math with them. I assume that you are familiar with the mathematical operations that we will discuss, and will instead focus on describing the notation used to perform the operations.\n",
    "\n",
    "We can add a scalar value to an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8510d3-a0d6-4a21-9e32-d8fb03410293",
   "metadata": {
    "id": "8c8510d3-a0d6-4a21-9e32-d8fb03410293"
   },
   "outputs": [],
   "source": [
    "myArray = np.array([1,2,3,4])\n",
    "newArray = np.array(myArray) + 1\n",
    "newArray"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8ada9c-7f50-40f4-aa3a-0b475f4fbf2c",
   "metadata": {
    "id": "6e8ada9c-7f50-40f4-aa3a-0b475f4fbf2c"
   },
   "source": [
    "Add (or subtract) arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82421852-4d2d-45b9-b5cb-5d1d3fa06112",
   "metadata": {
    "id": "82421852-4d2d-45b9-b5cb-5d1d3fa06112"
   },
   "outputs": [],
   "source": [
    "myArray - newArray # must have same shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc8efc0-7ff8-4327-b112-fdbb848aaf57",
   "metadata": {
    "id": "cdc8efc0-7ff8-4327-b112-fdbb848aaf57"
   },
   "source": [
    "And, critically, perform matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4ec09-340a-42da-8493-419b7f07c596",
   "metadata": {
    "id": "72c4ec09-340a-42da-8493-419b7f07c596"
   },
   "outputs": [],
   "source": [
    "myArray.T.dot(myArray) # to get 4 x 4 product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b8fa8d-b76d-4aae-b5a8-0f5d5a3691c5",
   "metadata": {
    "id": "26b8fa8d-b76d-4aae-b5a8-0f5d5a3691c5"
   },
   "source": [
    "We can also use the `@` operator to conduct matrix multiplication. It's much easier to read as math, but does the exact same thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059c6f1-d5b7-461f-ba44-12f46c088523",
   "metadata": {
    "id": "0059c6f1-d5b7-461f-ba44-12f46c088523"
   },
   "outputs": [],
   "source": [
    "myArray.T @ myArray # '@' only works in python >=3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e95757b-d1f4-4fd6-8748-a1d0823dc832",
   "metadata": {
    "id": "9e95757b-d1f4-4fd6-8748-a1d0823dc832"
   },
   "source": [
    "#### An Exercise Multiplying Matrices\n",
    "\n",
    "To get more familiar with how to use `numpy` to create useful functionality, let's write a function that accepts four arguments ($a$, $b$, $c$, and $x$), and calculates the output ($y$) of the following functional form:\n",
    "\n",
    "$$ y = a + b\\cdot x +c\\cdot x^2 $$\n",
    "\n",
    "Remember that we can solve systems of equations by converting the equations into matrices, and then use matrix multiplication to solve the entire system of equations in one operation. This might seem silly in a simple example, but this powerful ability to solve systems of equations with matrix algebra is the core of regression analysis and machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea111480-e1e7-4316-9e3f-401551928601",
   "metadata": {
    "id": "ea111480-e1e7-4316-9e3f-401551928601"
   },
   "outputs": [],
   "source": [
    "def squareFunc(a=1, b=1, c=1, x=1):\n",
    "    coef = np.array([a, b, c])\n",
    "    xs = np.array([1, x, x**2])\n",
    "    return coef @ xs # we can do the same math with coef.dot(xs)\n",
    "\n",
    "squareFunc(a=10, b=3, c=4, x=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7469f8f-f24c-4c91-9f77-5fc6bd416839",
   "metadata": {
    "id": "b7469f8f-f24c-4c91-9f77-5fc6bd416839"
   },
   "source": [
    "On top of making our math into a single operation, vectorized math using `numpy` is FAR more efficient computationally than loops and standard Python code. This doesn't matter for our current use case, but is very important when writing large scale code. In the end, our goal is to be able to code efficiently even where the data that we use is very large, so we want to focus on solutions that will scale with our data.\n",
    "\n",
    "Now that we have the ability to manipulate matrices, we have the first building blocks for constructing statistical models. We need a little bit extra help to make it convenient and fast to do all of the calculations, so we will spend the rest of this notebook looking at statistical functionality across `numpy` and `scipy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8749b06-13be-41ed-afca-c0457bf38474",
   "metadata": {
    "id": "c8749b06-13be-41ed-afca-c0457bf38474"
   },
   "source": [
    "## Stats in numpy and scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7e25e0-b48a-433f-82bd-c3fcce58e424",
   "metadata": {
    "id": "8a7e25e0-b48a-433f-82bd-c3fcce58e424"
   },
   "source": [
    "Because `numpy` and `scipy` are adaptations of code that existed before Python, our statistical functionality is spread across the two libraries. Some of the stats that we need will come from `numpy`, while other elements will come from `scipy`. For the most part, random sampling happens through `numpy`, and calculating distributional propoerties will happen through `scipy`. Let's start generating random numbers!\n",
    "\n",
    "### Random Numbers in `numpy`\n",
    "\n",
    "In case you need some justification for why random numbers are so useful, we generate random numbers for all sorts of tasks. We use random numbers to generate simulations. If we didn't, each simulation would be identical to the others. We use random numbers when we conduct bootstrapping procedures, so that we can sample randomly from available observations in order to generate a more complete understanding of the data and likelihood that what we have seen is what we expected to see. `numpy` has the functionality to allow us to generate many different and useful types of random numbers, and to do so quickly and easily.\n",
    "\n",
    "The code to generate random numbers is really simple, and also doubles as a great way to create arrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05b940-bb54-45e0-b82e-65c8e76a8b78",
   "metadata": {
    "id": "2c05b940-bb54-45e0-b82e-65c8e76a8b78"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.rand() # Generates a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918b11fd-2173-4112-944c-ec5a2cb8d8a3",
   "metadata": {
    "id": "918b11fd-2173-4112-944c-ec5a2cb8d8a3"
   },
   "outputs": [],
   "source": [
    "np.random.rand(3) # Array of 3 random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f272f0a-853d-49ef-993c-1972522a20db",
   "metadata": {
    "id": "0f272f0a-853d-49ef-993c-1972522a20db"
   },
   "outputs": [],
   "source": [
    "np.random.rand(5,5) # Create a 5 x 5 matrix of random numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5dcd80-7ef6-4746-b340-3ff9ac792bc5",
   "metadata": {
    "id": "2e5dcd80-7ef6-4746-b340-3ff9ac792bc5"
   },
   "source": [
    "This function draws from the uniform distribution, and can be utilized as the basis for ANY other random process. We won't have to do this very often, but if we start with a random number on the unit interval $[0, 1)$, we can generate any other distribution of random numbers. This is easily done in `numpy` via **Inverse Transform Sampling**. Let's use the uniform distribution to generate numbers from the *Exponential Distribution* with $\\lambda = 1$.\n",
    "\n",
    "First, we should look up the CDF of the Exponential Distribution, solve for $x$, and use it to generate values.\n",
    "\n",
    "$$F = 1-e^{-\\lambda x}=y $$\n",
    "$$ x = - ln(1-y)$$\n",
    "\n",
    "Inverse transform sampling is simply the process of using random uniform draws on the unit interval as sampled $y$ values (because the CDF of a distribution is always between 0 and 1). Once we have the CDF value, we can use that to work our way backward to the $x$ value from a given distribution that sits at that position on the CDF. We just need to write a function that draws a random sample of $y$ values, and then passes them through the equation we just solved for $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e4b54bd-fff3-452b-ac80-2207408d62cc",
   "metadata": {
    "id": "9e4b54bd-fff3-452b-ac80-2207408d62cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of X:\n",
      "   sex  age  educ  white\n",
      "0    2   32     7      1\n",
      "1    1   34     6      1\n",
      "2    1   93     4      1\n",
      "3    1   44     6      1\n",
      "4    2   34     8      1\n",
      "First few rows of Y:\n",
      "0    19000\n",
      "1    25000\n",
      "2        0\n",
      "3    40000\n",
      "4    32000\n",
      "Name: incwage, dtype: int64\n",
      "Shape of X: (13712, 5)\n",
      "Shape of Y: (13712,)\n",
      "Beta coefficients: [-13565.41062656   -234.99171879   5774.81872919   3404.1285002   13199.79799594]\n",
      "Residuals: [ -3377.10134599  -4697.70980577  -4283.56093866 ... -27077.24972118 -23822.91683597  26127.00139483]\n",
      "Residual sum of squares: 16013073243775.57\n",
      "Sigma squared: 1168240551.8184555\n",
      "Variance of beta: [3.42197466e+05 2.61916436e+02 2.04082012e+04 1.33789488e+06 3.58350289e+06]\n",
      "Standard errors of beta: [ 584.97646651   16.18383254  142.85727566 1156.67405918 1893.014235  ]\n",
      "T-statistics: [-23.18966899 -14.52015264  40.42369353   2.94303177   6.97289949]\n",
      "P-values: [5.03908615e-117 1.01516988e-047 0.00000000e+000 1.62779882e-003 1.62345179e-012]\n",
      "    Variable   Coefficient  Standard Error  t-statistic        p-value\n",
      "0        sex -13565.410627      584.976467   -23.189669  5.039086e-117\n",
      "1        age   -234.991719       16.183833   -14.520153   1.015170e-47\n",
      "2       educ   5774.818729      142.857276    40.423694   0.000000e+00\n",
      "3      white   3404.128500     1156.674059     2.943032   1.627799e-03\n",
      "4  intercept  13199.797996     1893.014235     6.972899   1.623452e-12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "class RegressionModel:\n",
    "    def __init__(self, x, y, create_intercept=True, regression_type=\"ols\"):\n",
    "        self.x = x.copy()\n",
    "        self.y = y\n",
    "        self.create_intercept = create_intercept\n",
    "        self.regression_type = regression_type\n",
    "        self.results = None\n",
    "\n",
    "        if self.create_intercept:\n",
    "            self.add_intercept()\n",
    "\n",
    "    def add_intercept(self):\n",
    "        \"\"\"Adds an intercept column to X if it doesn't already exist.\"\"\"\n",
    "        if 'intercept' not in self.x.columns:\n",
    "            self.x['intercept'] = 1\n",
    "\n",
    "    def ols_regression(self):\n",
    "        \"\"\"Performs Ordinary Least Squares regression.\"\"\"\n",
    "        X = self.x.values\n",
    "        Y = self.y.values\n",
    "\n",
    "        # Print the shape of X and Y\n",
    "        print(\"Shape of X:\", X.shape)\n",
    "        print(\"Shape of Y:\", Y.shape)\n",
    "        \n",
    "        X_transpose = X.T\n",
    "        beta, _, _, _ = np.linalg.lstsq(X, Y, rcond=None)  \n",
    "\n",
    "        # Print the beta coefficients\n",
    "        print(\"Beta coefficients:\", beta)\n",
    "\n",
    "        residuals = Y - X.dot(beta)\n",
    "        residual_sum_of_squares = residuals.T.dot(residuals)\n",
    "        \n",
    "        # Print the residuals and sum of squares\n",
    "        print(\"Residuals:\", residuals)\n",
    "        print(\"Residual sum of squares:\", residual_sum_of_squares)\n",
    "\n",
    "        sigma_squared = residual_sum_of_squares / (X.shape[0] - X.shape[1])\n",
    "\n",
    "        # Print sigma squared\n",
    "        print(\"Sigma squared:\", sigma_squared)\n",
    "\n",
    "        var_beta = sigma_squared * np.linalg.pinv(X_transpose.dot(X)).diagonal()\n",
    "        std_err_beta = np.sqrt(var_beta)\n",
    "\n",
    "        # Print the variance and standard errors of the coefficients\n",
    "        print(\"Variance of beta:\", var_beta)\n",
    "        print(\"Standard errors of beta:\", std_err_beta)\n",
    "\n",
    "        t_stats = beta / std_err_beta\n",
    "        p_values = stats.t.sf(np.abs(t_stats), df=X.shape[0] - X.shape[1])\n",
    "\n",
    "        # Print the t-stats and p-values\n",
    "        print(\"T-statistics:\", t_stats)\n",
    "        print(\"P-values:\", p_values)\n",
    "\n",
    "        self.results = {}\n",
    "        for i, var in enumerate(self.x.columns):\n",
    "            self.results[var] = {\n",
    "                \"coefficient\": beta[i],\n",
    "                \"standard_error\": std_err_beta[i],\n",
    "                \"t_stat\": t_stats[i],\n",
    "                \"p_value\": p_values[i]\n",
    "            }\n",
    "\n",
    "    def summary(self):\n",
    "        if self.results is None:\n",
    "            raise ValueError(\"No regression results found. Run ols_regression() first.\")\n",
    "\n",
    "        summary_data = [\n",
    "            [var, stats[\"coefficient\"], stats[\"standard_error\"], stats[\"t_stat\"], stats[\"p_value\"]]\n",
    "            for var, stats in self.results.items()\n",
    "        ]\n",
    "\n",
    "        return pd.DataFrame(summary_data, columns=[\"Variable\", \"Coefficient\", \"Standard Error\", \"t-statistic\", \"p-value\"])\n",
    "\n",
    "# Load the dataset from CSV file\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# File path to the CSV file\n",
    "file_path = r\"C:\\Users\\mquint\\OneDrive - Loyola University Chicago\\Desktop\\assignment8Data.csv\"\n",
    "\n",
    "data = load_data(file_path)\n",
    "\n",
    "# Select specific columns for X and y\n",
    "X = data[['sex', 'age', 'educ', 'white']]  # Independent variables\n",
    "Y = data['incwage']  # Dependent variable\n",
    "\n",
    "# Drop missing values and infinite values in X and ensure Y matches X's index\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "Y = Y.loc[X.index]\n",
    "\n",
    "# Print the first few rows of X and Y\n",
    "print(\"First few rows of X:\")\n",
    "print(X.head())\n",
    "print(\"First few rows of Y:\")\n",
    "print(Y.head())\n",
    "\n",
    "# Create and run regression model\n",
    "model = RegressionModel(X, Y)\n",
    "model.ols_regression()\n",
    "\n",
    "# Print summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de899673-4584-4018-bac4-f9671b992cd5",
   "metadata": {
    "id": "de899673-4584-4018-bac4-f9671b992cd5",
    "tags": []
   },
   "source": [
    "And now we have 10 random values drawn from the exponential distribution! Like with our hand-made matrix operations, we really don't need to do this, though! Instead, we can simply use the built-in random number generators within `numpy`. Some common distributions to draw from:\n",
    "- `np.random.rand` - Random uniform draws on the unit interval\n",
    "- `np.random.randint` - Random draws among integers\n",
    "- `np.random.beta` - Random draws from the beta distribution\n",
    "- `np.random.normal` - Random draws from the normal distribution\n",
    "- `np.random.poisson` - Random draws from the Poisson distribution\n",
    "\n",
    "There are a ton more, and you can see them all [here](https://numpy.org/doc/stable/reference/random/legacy.html).\n",
    "\n",
    "### Random Numbers and Pandas!\n",
    "\n",
    "It turns out that `pandas` uses these random sampling capabilities behind the scenes. We see it in action when we use the `.sample(n)` method to sample from a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af548c-c47e-4fd4-bcc6-a3bcdcfbe90b",
   "metadata": {
    "id": "21af548c-c47e-4fd4-bcc6-a3bcdcfbe90b"
   },
   "outputs": [],
   "source": [
    "sampled_data = full_data_name.sample(10000, replace=False) # Don't run, we don't have any data loaded. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3bf91f-06cd-4347-bde3-864e36c3a938",
   "metadata": {
    "id": "be3bf91f-06cd-4347-bde3-864e36c3a938"
   },
   "source": [
    "### Distributional Calculations\n",
    "\n",
    "While it is great to be able to *sample* from statistical distributions, it is also helpful to be able to calculate various statistics when we know that a particular distribution is generating our data. `scipy` includes [functions for calculating properties from most distributions](https://docs.scipy.org/doc/scipy/reference/stats.html):\n",
    "\n",
    "Example: [Normal Distribution](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm)\n",
    "\n",
    "Example: [Student's t Distribution](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html#scipy.stats.t)\n",
    "\n",
    "We can use this functionality when we build out statistical tests on regression analysis. These distributions include the ability to make calculations using the PDF, CDF, survival function, and many more parameters that are of interest in different contexts. Let's check it out with the normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc3d1a1b-5cfc-4b54-b36b-888c245795a3",
   "metadata": {
    "id": "bc3d1a1b-5cfc-4b54-b36b-888c245795a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable name  coefficient value  standard error  t-statistic       p-value\n",
      "          sex      -13565.410627      584.976467   -23.189669 5.039086e-117\n",
      "          age        -234.991719       16.183833   -14.520153  1.015170e-47\n",
      "         educ        5774.818729      142.857276    40.423694  0.000000e+00\n",
      "        white        3404.128500     1156.674059     2.943032  1.627799e-03\n",
      "    intercept       13199.797996     1893.014235     6.972899  1.623452e-12\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "class RegressionModel:\n",
    "    def __init__(self, x, y, create_intercept=True, regression_type=\"ols\"):\n",
    "        if not isinstance(x, pd.DataFrame):\n",
    "            raise ValueError(\"x should be a pandas DataFrame\")\n",
    "        if not isinstance(y, pd.DataFrame) and not isinstance(y, pd.Series):\n",
    "            raise ValueError(\"y should be a pandas DataFrame or Series\")\n",
    "        if regression_type != \"ols\":\n",
    "            raise ValueError(\"regression_type should be 'ols'\")\n",
    "\n",
    "        # Store x and y as attributes\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.create_intercept = create_intercept\n",
    "        self.regression_type = regression_type\n",
    "        self.results = None\n",
    "\n",
    "        # Add intercept if required\n",
    "        if self.create_intercept:\n",
    "            self.add_intercept()\n",
    "\n",
    "    def add_intercept(self):\n",
    "        \"\"\"Adds an intercept column (a column of ones) to X if create_intercept is True.\"\"\"\n",
    "        if self.create_intercept:\n",
    "            # Add a column of ones to the DataFrame for the intercept\n",
    "            self.x['intercept'] = 1\n",
    "\n",
    "    def ols_regression(self):\n",
    "        \"\"\"Performs Ordinary Least Squares (OLS) regression and stores the results in `results`.\"\"\"\n",
    "        # Get the numpy array representations of x and y\n",
    "        x = self.x.values\n",
    "        y = self.y.values\n",
    "\n",
    "        # Perform the OLS regression using np.linalg.lstsq for numerical stability\n",
    "        beta, _, _, _ = np.linalg.lstsq(x, y, rcond=None)\n",
    "\n",
    "        # Calculate residuals and residual sum of squares\n",
    "        residuals = y - x.dot(beta)\n",
    "        residual_sum_of_squares = residuals.T.dot(residuals)\n",
    "\n",
    "        # Calculate sigma squared (variance of residuals)\n",
    "        sigma_squared = residual_sum_of_squares / (x.shape[0] - x.shape[1])\n",
    "\n",
    "        # Calculate variance of beta coefficients and standard errors\n",
    "        var_beta = sigma_squared * np.linalg.pinv(x.T.dot(x)).diagonal()\n",
    "        std_err_beta = np.sqrt(var_beta)\n",
    "\n",
    "        # Calculate t-statistics for each coefficient\n",
    "        t_stats = beta / std_err_beta\n",
    "\n",
    "        # Store results in a dictionary, explicitly casting each value to float\n",
    "        self.results = {\n",
    "            var: {\n",
    "                \"coefficient value\": float(beta[i]),\n",
    "                \"standard error\": float(std_err_beta[i]),\n",
    "                \"t-statistic\": float(t_stats[i]),\n",
    "                \"p-value\": float(stats.t.sf(np.abs(t_stats[i]), df=x.shape[0] - x.shape[1]))  # One-tailed p-value calculation\n",
    "            }\n",
    "            for i, var in enumerate(self.x.columns)\n",
    "        }\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Fit the regression model (currently only OLS).\"\"\"\n",
    "        if self.regression_type == \"ols\":\n",
    "            self.ols_regression()\n",
    "\n",
    "    def summary(self):\n",
    "        if self.results is None:\n",
    "            raise ValueError(\"No regression results found. Run fit() first.\")\n",
    "\n",
    "        # Create a DataFrame to summarize the results\n",
    "        summary_data = [\n",
    "            [var, stats[\"coefficient value\"], stats[\"standard error\"], stats[\"t-statistic\"], stats[\"p-value\"]]\n",
    "            for var, stats in self.results.items()\n",
    "        ]\n",
    "\n",
    "        # Create a DataFrame and set the column names\n",
    "        summary_df = pd.DataFrame(summary_data, columns=[\"Variable name\", \"coefficient value\", \"standard error\", \"t-statistic\", \"p-value\"])\n",
    "\n",
    "        # Return the summary as a formatted table (as a string)\n",
    "        return summary_df.to_string(index=False)\n",
    "\n",
    "# Function to load data\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# File path to the CSV file (replace with your own file path)\n",
    "file_path = r\"C:\\Users\\mquint\\OneDrive - Loyola University Chicago\\Desktop\\assignment8Data.csv\"\n",
    "\n",
    "data = load_data(file_path)\n",
    "\n",
    "# Select specific columns for X and y\n",
    "x = data[['sex', 'age', 'educ', 'white']]  # Independent variables (exogenous)\n",
    "y = data['incwage']  # Dependent variable (endogenous)\n",
    "\n",
    "# Drop missing values and infinite values in x and ensure y matches x's index\n",
    "x = x.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y.loc[x.index]\n",
    "\n",
    "# Create and run regression model (OLS only)\n",
    "model = RegressionModel(x, y, create_intercept=True, regression_type=\"ols\")\n",
    "model.fit()\n",
    "\n",
    "# Print summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab050b1-2fe8-4dcf-8605-c8f9535fa7ff",
   "metadata": {
    "id": "0ab050b1-2fe8-4dcf-8605-c8f9535fa7ff"
   },
   "source": [
    "So we can see that, for a standard normal distribution, the position `x=1.96` (which is also 1.96 standard deviations away from the mean) is associated with a probability of ~2.5% that a new draw would be higher than this point. That's why z-statistics of 1.96 or above are considered statistically significant at the 5% level for a two-tailed test (2.5% * 2 tails = 5%).\n",
    "\n",
    "We can calculate many other properties of the normal distribution. What is the likelihood that a draw from the random normal distribution would fall between 0 and 1? Let's find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6915bd80-7071-44c6-ab37-05302a99f5c8",
   "metadata": {
    "id": "6915bd80-7071-44c6-ab37-05302a99f5c8"
   },
   "outputs": [],
   "source": [
    "norm.cdf(1) - norm.cdf(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78181a56-82dc-4093-a045-f1c79c18bc29",
   "metadata": {
    "id": "78181a56-82dc-4093-a045-f1c79c18bc29"
   },
   "source": [
    "So 34% of draws would be expected to fall in that interval! If we use our `numpy` sampling tools, we can verify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d16d30-26dc-420f-90be-3c1d4ac226bd",
   "metadata": {
    "id": "d7d16d30-26dc-420f-90be-3c1d4ac226bd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40408e3f-5dc4-4455-8a23-adb794a72eea",
   "metadata": {
    "id": "40408e3f-5dc4-4455-8a23-adb794a72eea"
   },
   "source": [
    "Crazy! My draw got exactly 34/100 observations between 0 and 1. If we keep sampling, we will see other values as the sample changes, but it will generally be pretty close to our estimate!\n",
    "\n",
    "Let's put all these skills to work and build some statistical tools. It's time to make a regression algorithm!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4612551b-529c-4ec3-9dda-55e29723e230",
   "metadata": {
    "id": "4612551b-529c-4ec3-9dda-55e29723e230"
   },
   "source": [
    "**Solve it!**\n",
    "\n",
    "In this lesson we learned about numeric libraries in Python, specifically NumPy and SciPy. For the assignment this week, I would like you to code a class called `RegressionModel`, that will calculate all the values typically presented in the primary regression table by statistical software. You can see an example in the image below:\n",
    "\n",
    "![](https://blog.minitab.com/hubfs/Imported_Blog_Media/regr_p_values.gif)\n",
    "\n",
    "Your job is to create the following functionality within your class object:\n",
    "\n",
    "- your class should take arguments for `x`, `y`, `create_intercept`, and `regression_type`\n",
    "    - x and y should be data frames\n",
    "    - create_intercept should be a binary variable (True or False)\n",
    "    - regression_type should be a string, containing either `\"ols\"` or `\"logit\"` (we won't work with the logistic part this week... that is for next week)\n",
    "- attributes `x` and `y` that store the exogenous and endogenous variables used in your regression\n",
    "- a method (call it `add_intercept`) that adds a column of ones to the data frame `x` if create_intercept has a value of `True`. This can also be completed without a method if you so choose. Name the column `intercept`.\n",
    "- a method (call it `ols_regression`) that estimates the results of ordinary least squares regression using your x and y data frames.\n",
    "    - the results should be stored in a dictionary named `results`, where each variable name (including the intercept if `create_intercept` is True) is the key, and the value is another dictionary, with keys for `coefficient`, `standard_error`, `t_stat`, and `p_value`.\n",
    "- a method (call it `summary`) that presents your regression results in a table, similar to the first 5 columns of the table above\n",
    "    - Columns should be: `\"Variable name\"`, `\"coefficient value\"`, `\"standard error\"`, `\"t-statistic\"`, and `\"p-value\"`, in that order.\n",
    "\n",
    "**You only need to define the class**. My code will create an instance of your class (be sure all the names match these instructions!), and provide data to run a regression. I will provide the same data to you, so that you can experiment and make sure that your code is functioning properly.\n",
    "\n",
    "Put code that you want graded in the cell commented `#si-exercise` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adbc4202-9586-4e18-b8d6-54291c2174f1",
   "metadata": {
    "id": "adbc4202-9586-4e18-b8d6-54291c2174f1"
   },
   "outputs": [],
   "source": [
    "#si-exercise\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "class RegressionModel:\n",
    "    def __init__(self, x: pd.DataFrame, y: pd.Series, create_intercept: bool = True, regression_type: str = \"ols\"):\n",
    "\n",
    "        # Store the exogenous (x) and endogenous (y) variables as attributes\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.create_intercept = create_intercept\n",
    "        self.regression_type = regression_type\n",
    "\n",
    "        # Check if regression_type is valid\n",
    "        if self.regression_type != \"ols\":\n",
    "            raise ValueError(f\"Unsupported regression type: {self.regression_type}\")\n",
    "\n",
    "        # Add intercept if specified\n",
    "        if self.create_intercept:\n",
    "            self.add_intercept()\n",
    "\n",
    "        # Perform OLS regression\n",
    "        self.ols_regression()\n",
    "\n",
    "    def add_intercept(self):\n",
    "        \"\"\"Adds an intercept (column of ones) to the exogenous variable DataFrame.\"\"\"\n",
    "        self.x['intercept'] = 1\n",
    "\n",
    "    def ols_regression(self):\n",
    "        \"\"\"Manually estimates the results of ordinary least squares regression and stores them in a dictionary.\"\"\"\n",
    "        # Convert x and y into numpy arrays for matrix operations\n",
    "        X = self.x.values\n",
    "        y = self.y.values\n",
    "\n",
    "        # Calculate the OLS coefficients (beta)\n",
    "        X_transpose = X.T\n",
    "        beta = np.linalg.inv(X_transpose.dot(X)).dot(X_transpose).dot(y)\n",
    "\n",
    "        # Calculate the predicted values (y-hat)\n",
    "        y_hat = X.dot(beta)\n",
    "\n",
    "        # Calculate residuals (y - y-hat)\n",
    "        residuals = y - y_hat\n",
    "\n",
    "        # Calculate mean squared error (MSE)\n",
    "        mse = np.sum(residuals**2) / (X.shape[0] - X.shape[1])\n",
    "\n",
    "        # Calculate the variance-covariance matrix of the coefficients\n",
    "        var_beta = mse * np.linalg.inv(X_transpose.dot(X))\n",
    "\n",
    "        # Calculate standard errors of the coefficients\n",
    "        std_errors = np.sqrt(np.diagonal(var_beta))\n",
    "\n",
    "        # Calculate t-statistics (beta / standard_error)\n",
    "        t_stats = beta / std_errors\n",
    "\n",
    "        # Calculate one-tailed p-values based on the sign of t-statistics\n",
    "        p_values = []\n",
    "        for t_stat in t_stats:\n",
    "            if t_stat > 0:\n",
    "                p_values.append(1 - stats.t.cdf(t_stat, df=X.shape[0] - X.shape[1]))  # Right tail\n",
    "            else:\n",
    "                p_values.append(stats.t.cdf(t_stat, df=X.shape[0] - X.shape[1]))  # Left tail\n",
    "\n",
    "        # Store the results in a dictionary\n",
    "        self.results = {}\n",
    "        for i, variable in enumerate(self.x.columns):\n",
    "            self.results[variable] = {\n",
    "                'coefficient': beta[i],\n",
    "                'standard_error': std_errors[i],\n",
    "                't_stat': t_stats[i],\n",
    "                'p_value': p_values[i]\n",
    "            }\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"Presents the regression results in a table.\"\"\"\n",
    "        # Create a pandas DataFrame for the summary\n",
    "        summary_data = {\n",
    "            \"Variable name\": [],\n",
    "            \"Coefficient value\": [],\n",
    "            \"Standard error\": [],\n",
    "            \"T-statistic\": [],\n",
    "            \"P-value\": []\n",
    "        }\n",
    "        \n",
    "        # Add results to the summary data\n",
    "        for variable in self.results:\n",
    "            summary_data[\"Variable name\"].append(variable)\n",
    "            summary_data[\"Coefficient value\"].append(self.results[variable]['coefficient'])\n",
    "            summary_data[\"Standard error\"].append(self.results[variable]['standard_error'])\n",
    "            summary_data[\"T-statistic\"].append(self.results[variable]['t_stat'])\n",
    "            summary_data[\"P-value\"].append(self.results[variable]['p_value'])\n",
    "\n",
    "        # Convert summary_data to a pandas DataFrame and display\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        print(summary_df)\n",
    "\n",
    "\n",
    "def load_data_from_csv(file_path: str, dependent_var: str, independent_vars: list):\n",
    "    \"\"\"Loads data from a CSV file and prepares x and y for regression.\"\"\"\n",
    "    # Load the data from CSV into a pandas DataFrame\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Prepare the independent variables (x) and dependent variable (y)\n",
    "    x = data[independent_vars]\n",
    "    y = data[dependent_var]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
